{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image, ImageDraw, ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.15, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in NTNU_Herbarium_Segmentation_V2-7 to yolov8:: 100%|██████████| 145360/145360 [00:14<00:00, 10100.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to NTNU_Herbarium_Segmentation_V2-7 in yolov8:: 100%|██████████| 224/224 [00:00<00:00, 1274.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"x5pZ44ydkd9As40Mglzv\")\n",
    "project = rf.workspace(\"ntnuscaledetection\").project(\"ntnu_herbarium_segmentation_v2\")\n",
    "version = project.version(7)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_version = version.version\n",
    "\n",
    "dataset_img = sorted(os.listdir(f'./NTNU_Herbarium_Segmentation_V2-{dataset_version}/train/images'))\n",
    "dataset_mask = sorted(os.listdir(f'./NTNU_Herbarium_Segmentation_V2-{dataset_version}/train/labels'))\n",
    "\n",
    "for idx, (img, mask) in enumerate(zip(dataset_img, dataset_mask)):\n",
    "    new_name = img.split('.')[0].replace('_jpg', '')\n",
    "    os.rename(f'./NTNU_Herbarium_Segmentation_V2-{dataset_version}/train/images/{img}', f'./NTNU_Herbarium_Segmentation_V2-{dataset_version}/train/images/{new_name}.png')\n",
    "    os.rename(f'./NTNU_Herbarium_Segmentation_V2-{dataset_version}/train/labels/{mask}', f'./NTNU_Herbarium_Segmentation_V2-{dataset_version}/train/labels/{new_name}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only selecting a few (manually chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['1701328720_a', '1701332829', '1701257719', '1701235632', '1701246629', '1701268081', '1701233161']\n",
    "\n",
    "os.makedirs('./to_augment/images', exist_ok=True)\n",
    "os.makedirs('./to_augment/labels', exist_ok=True)\n",
    "\n",
    "for img in selected:\n",
    "    os.rename(f'./NTNU_Herbarium_Segmentation_V2-{dataset_version}/train/images/{img}.png', f'./to_augment/images/{img}.png')\n",
    "    os.rename(f'./NTNU_Herbarium_Segmentation_V2-{dataset_version}/train/labels/{img}.png', f'./to_augment/labels/{img}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping out the masks and saving them in binary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_points(label_path):\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.strip().split(' ')[1:] for line in lines] # remove the first element which is the class label\n",
    "    points = [[[float(line[i]), float(line[i+1])] for i in range(0, len(line), 2)] for line in lines] # convert to list of list of points where x and y are combined\n",
    "    return points\n",
    "\n",
    "def find_dominant_color(image: Image, k: int = 5) -> tuple:\n",
    "    \n",
    "    # Convert image to numpy array\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # Reshape it to a list of RGB values\n",
    "    img_vector = img_array.reshape((-1, 3))\n",
    "    \n",
    "    # Run k-means on the pixel colors\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(img_vector)\n",
    "    \n",
    "    # Get the dominant color\n",
    "    dominant_color = kmeans.cluster_centers_[np.argmax(np.bincount(kmeans.labels_))]\n",
    "    \n",
    "    # Create a mask for pixels within a certain distance from the dominant color\n",
    "    distances = np.sqrt(np.sum((img_vector - dominant_color) ** 2, axis=1))\n",
    "    mask = distances < np.std(distances)\n",
    "    \n",
    "    # Turn the dominant color range to white\n",
    "    img_vector[mask] = [255, 255, 255]\n",
    "    result_img_array = img_vector.reshape(img_array.shape)\n",
    "\n",
    "    return dominant_color, result_img_array\n",
    "\n",
    "def crop_out_image(image_path, points):\n",
    "\n",
    "    image = Image.open(image_path) # open the image\n",
    "    _, white_bg = find_dominant_color(image) # find the dominant color\n",
    "    white_bg = Image.fromarray(white_bg) # convert to image\n",
    "    image = white_bg.convert('RGBA') # convert to RGBA\n",
    "\n",
    "    for idx, point in enumerate(points):\n",
    "\n",
    "        mask = Image.new('L', image.size, 0) # create a mask\n",
    "        draw = ImageDraw.Draw(mask)\n",
    "\n",
    "        unnormalized_points = [(int(x * image.width), int(y * image.height)) for [x, y] in point] # un-normalize the points\n",
    "\n",
    "        draw.polygon(unnormalized_points, fill=255)\n",
    "\n",
    "        transparent_bg = Image.new('RGBA', image.size, (0, 0, 0, 0)) # create a white background\n",
    "\n",
    "        result = Image.composite(image, transparent_bg, mask) # crop out the image\n",
    "\n",
    "        # Turn all the white pixels to transparent\n",
    "        data = np.array(result)\n",
    "        white = np.all(data[:, :, :3] == 255, axis=-1)\n",
    "        data[white, -1] = 0\n",
    "        result = Image.fromarray(data)\n",
    "\n",
    "        name = os.path.basename(image_path).split('.')[0]\n",
    "        result.save(f'{name}_object_{idx}.png', 'PNG')\n",
    "\n",
    "def remove_objects_from_image(image_path, points):\n",
    "    image = Image.open(image_path) # open the image\n",
    "    _, result_img_array = find_dominant_color(image) # find the dominant color\n",
    "    image = Image.fromarray(result_img_array) # convert the numpy array to image\n",
    "\n",
    "    for point in points:\n",
    "\n",
    "        unnormalized_points = [(int(x * image.width), int(y * image.height)) for [x, y] in point] # un-normalize the points\n",
    "\n",
    "        ImageDraw.Draw(image).polygon(unnormalized_points, fill='white') # fill the polygon with white color\n",
    "\n",
    "    name = os.path.basename(image_path).split('.')[0]\n",
    "    image.save(f'{name}_augmented_0.png', 'PNG')\n",
    "\n",
    "def rotate_point(cx, cy, angle, px, py):\n",
    "    radians = np.radians(angle)\n",
    "    cos_angle = np.cos(radians)\n",
    "    sin_angle = np.sin(radians)\n",
    "    px -= cx\n",
    "    py -= cy\n",
    "    xnew = px * cos_angle - py * sin_angle\n",
    "    ynew = px * sin_angle + py * cos_angle\n",
    "    px = xnew + cx\n",
    "    py = ynew + cy\n",
    "    return px, py\n",
    "\n",
    "def update_points(points, perc_offset_x, perc_offset_y, rotation_angle, image_width, image_height):\n",
    "    # Calculate pixel offsets from percentages\n",
    "    offset_x = perc_offset_x * image_width / 100\n",
    "    offset_y = perc_offset_y * image_height / 100\n",
    "\n",
    "    # Image center as rotation center\n",
    "    rotation_center = (image_width / 2, image_height / 2)\n",
    "\n",
    "    # Rotate and then translate points\n",
    "    updated_points = []\n",
    "    for x, y in points:\n",
    "        new_x, new_y = rotate_point(rotation_center[0], rotation_center[1], rotation_angle, x, y)\n",
    "        new_x += offset_x\n",
    "        new_y += offset_y\n",
    "        updated_points.append((new_x, new_y))\n",
    "    return updated_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name = '1701233161'\n",
    "image_extension = 'png'\n",
    "original_points = get_mask_points(f'./to_augment/labels/{image_name}.txt')\n",
    "\n",
    "\n",
    "original_image = Image.open(f'./to_augment/images/{image_name}.{image_extension}')\n",
    "image_width, image_height = original_image.size\n",
    "\n",
    "remove_objects_from_image(f'./to_augment/images/{image_name}.{image_extension}', original_points)\n",
    "crop_out_image(f'./to_augment/images/{image_name}.{image_extension}', original_points)\n",
    "\n",
    "len(original_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually update the settings dictionary with the changes you made in the photo-editing software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    '0': {\n",
    "        'x_perc_offset': -27.47,\n",
    "        'y_perc_offset': -5.69,\n",
    "        'rotation_angle': -37.77\n",
    "    },\n",
    "    '1': {\n",
    "        'x_perc_offset': 8.70,\n",
    "        'y_perc_offset': -14.06,\n",
    "        'rotation_angle': -173.29\n",
    "    },\n",
    "    '2': {\n",
    "        'x_perc_offset': -4.62,\n",
    "        'y_perc_offset': -54.21,\n",
    "        'rotation_angle': -14.47\n",
    "    },\n",
    "    # '3': {\n",
    "    #     'x_perc_offset': 21.45,\n",
    "    #     'y_perc_offset': 33.06,\n",
    "    #     'rotation_angle': -3.74\n",
    "    # },\n",
    "    # '4': {\n",
    "    #     'x_perc_offset': 5.29,\n",
    "    #     'y_perc_offset': 60.88,\n",
    "    #     'rotation_angle': 0\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./augmented/images', exist_ok=True)\n",
    "os.makedirs('./augmented/labels', exist_ok=True)\n",
    "\n",
    "for idx, point in enumerate(original_points):\n",
    "\n",
    "    if idx >= len(settings):\n",
    "        break\n",
    "    \n",
    "    unnormalized_points = [(int(x * image_width), int(y * image_height)) for [x, y] in point]\n",
    "    \n",
    "    x_perc_offset = settings[str(idx)]['x_perc_offset']\n",
    "    y_perc_offset = settings[str(idx)]['y_perc_offset']\n",
    "    rotation_angle = settings[str(idx)]['rotation_angle']\n",
    "\n",
    "    new_points = update_points(unnormalized_points, x_perc_offset, y_perc_offset, rotation_angle, image_width, image_height)\n",
    "\n",
    "    with open(f'./augmented/labels/{image_name}_augmented_0.txt', 'a') as f:\n",
    "        f.write('0 ')\n",
    "        for x, y in new_points:\n",
    "            f.write(f'{x/image_width} {y/image_height}')\n",
    "            f.write(' ')\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
