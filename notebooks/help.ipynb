{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency ultralytics==8.0.196 is required but found version=8.1.34, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Ntnu_segmentation-16 to yolov8:: 100%|██████████| 14550/14550 [00:02<00:00, 6960.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Ntnu_segmentation-16 in yolov8:: 100%|██████████| 521/521 [00:00<00:00, 16064.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"x5pZ44ydkd9As40Mglzv\")\n",
    "project = rf.workspace(\"ntnuscaledetection\").project(\"ntnu_segmentation\")\n",
    "version = project.version(16)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.1.34, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Ntnu_segmentation-10 to yolov8:: 100%|██████████| 2731/2731 [00:00<00:00, 2856.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Ntnu_segmentation-10 in yolov8:: 100%|██████████| 87/87 [00:00<00:00, 5856.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.functional import adjust_hue\n",
    "from torchvision import transforms\n",
    "from roboflow import Roboflow\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def hue_degree_to_hue_value():\n",
    "    return (torch.rand(1).item() * 60 - 30) / 360.0  # Random hue between -30 and +30 degrees\n",
    "\n",
    "def augment_image(pil_img, name):\n",
    "    images = [pil_img.copy()]  # Start with the original image\n",
    "\n",
    "    # Apply a noticeable hue shift\n",
    "    hue_adjustment = hue_degree_to_hue_value()\n",
    "    images.append(adjust_hue(pil_img.copy(), hue_adjustment))\n",
    "\n",
    "    # Apply a more pronounced saturation change\n",
    "    images.append(transforms.ColorJitter(saturation=0.5)(pil_img.copy()))  # 50% less to 50% more saturation\n",
    "\n",
    "    # Apply a more noticeable brightness change\n",
    "    images.append(transforms.ColorJitter(brightness=0.5)(pil_img.copy()))  # 50% darker to 50% brighter\n",
    "\n",
    "    # Apply a stronger contrast change\n",
    "    images.append(transforms.ColorJitter(contrast=0.5)(pil_img.copy()))  # 50% less to 50% more contrast\n",
    "\n",
    "    names = [name] + [name.replace('.jpg', '_hue.jpg'), name.replace('.jpg', '_sat.jpg'), name.replace('.jpg', '_bright.jpg'), name.replace('.jpg', '_cont.jpg')]\n",
    "    return images, names\n",
    "\n",
    "def augment_images(image_paths):\n",
    "    augmented_batch = []\n",
    "    for img_path in image_paths:\n",
    "        pil_img = Image.open(img_path)  # Open the image file\n",
    "        augmented_batch.append((augment_image(pil_img, os.path.basename(img_path))))  # Apply augmentation and extend the batch list\n",
    "    return augmented_batch\n",
    "\n",
    "# download dataset\n",
    "rf = Roboflow(api_key=\"x5pZ44ydkd9As40Mglzv\")\n",
    "project = rf.workspace(\"ntnuscaledetection\").project(\"ntnu_segmentation\")\n",
    "version = project.version(10)\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n",
    "# get paths\n",
    "path = os.path.join(dataset.location, 'train', 'images')\n",
    "label_path = os.path.join(dataset.location, 'train', 'labels')\n",
    "\n",
    "image_paths = [os.path.join(path, i) for i in os.listdir(path) if i.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# augment images\n",
    "augmented_images = augment_images(image_paths)\n",
    "\n",
    "# save images and labels\n",
    "for idx, item in enumerate(augmented_images):\n",
    "    original_name = item[1][0].replace('.jpg', '.txt')\n",
    "    original_label = os.path.join(label_path, original_name)\n",
    "    # copy original label with new names (hue, sat, bright, cont)\n",
    "    for name in item[1][1:]:\n",
    "        new_label = os.path.join(label_path, name.replace('.jpg', '.txt'))\n",
    "        shutil.copy(original_label, new_label)\n",
    "    \n",
    "    # save images\n",
    "    for name, image in zip(item[1], item[0]):\n",
    "        image.save(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.1.34, to fix: `pip install ultralytics==8.0.196`\n",
      "View the status of your deployment at: https://app.roboflow.com/ntnuscaledetection/ntnu_segmentation/5\n",
      "Share your model with the world at: https://universe.roboflow.com/ntnuscaledetection/ntnu_segmentation/model/5\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"x5pZ44ydkd9As40Mglzv\")\n",
    "project = rf.workspace(\"ntnuscaledetection\").project(\"ntnu_segmentation\")\n",
    "version = project.version(5)\n",
    "version.deploy(\"yolov8-seg\", \"../models\", \"plant_segmentation_v6.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1m/home/floris/Projects/NTNU/models/runs/segment/predict2\u001b[0m\n",
      "Results saved to \u001b[1m/home/floris/Projects/NTNU/models/runs/segment/predict3\u001b[0m\n",
      "Results saved to \u001b[1m/home/floris/Projects/NTNU/models/runs/segment/predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "images = [os.path.join('../images/gbif_images', image) for image in os.listdir('../images/gbif_images')]\n",
    "\n",
    "\n",
    "for batch in range(0, len(images), 10):\n",
    "    model = YOLO('../models/plant_segmentation_v10.pt')\n",
    "    res = model(images[batch:batch+10], save=True, iou=0.4, conf=0.6, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "path = '../models/runs/segment'\n",
    "save_path = '/home/floris/Projects/NTNU/images/segment_eval/v9'\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "preds = os.listdir(path)\n",
    "for dir in preds:\n",
    "    for img in os.listdir(os.path.join(path, dir)):\n",
    "        shutil.move(os.path.join(path, dir, img), save_path)\n",
    "        \n",
    "shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def resize_image_with_aspect_ratio(img_path, target_width, target_height):\n",
    "    # Open the original image\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # Calculate the ratio of the target dimensions\n",
    "    target_ratio = target_width / target_height\n",
    "    # Calculate the ratio of the original dimensions\n",
    "    img_ratio = img.width / img.height\n",
    "    \n",
    "    # Determine the size to which the original image is to be resized\n",
    "    if img_ratio > target_ratio:\n",
    "        # Width is the limiting dimension\n",
    "        new_width = target_width\n",
    "        new_height = round(target_width / img_ratio)\n",
    "    else:\n",
    "        # Height is the limiting dimension\n",
    "        new_height = target_height\n",
    "        new_width = round(target_height * img_ratio)\n",
    "    \n",
    "    # Resize the original image\n",
    "    resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Create a new image with a black background and the target size\n",
    "    new_img = Image.new(\"RGB\", (target_width, target_height), (0, 0, 0))\n",
    "    \n",
    "    # Calculate the position to paste the resized image onto the new image\n",
    "    x = (target_width - new_width) // 2\n",
    "    y = (target_height - new_height) // 2\n",
    "    \n",
    "    # Paste the resized image onto the new image\n",
    "    new_img.paste(resized_img, (x, y))\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "\n",
    "image = cv2.imread('../images/upload/1802796785.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('../models/plant_segmentation_v2.pt')\n",
    "results = model(image)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "new_image = resize_image_with_aspect_ratio('../images/upload/1802796785.jpg', 640, 640)\n",
    "\n",
    "plt.imshow(new_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
