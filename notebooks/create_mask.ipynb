{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "images = '../images/gbif_images'\n",
    "save_dir = \"../data/to_edit\"\n",
    "image_save_dir = \"../data/dataset/images\"\n",
    "label_save_dir = \"../data/dataset/labels\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(image_save_dir, exist_ok=True)\n",
    "os.makedirs(label_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create masks to edit and move images to dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(images):\n",
    "    # Load the image in grayscale mode\n",
    "    orig = cv2.imread(os.path.join(images, image), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Apply Otsu's thresholding to segment the image\n",
    "    ret, thresh = cv2.threshold(orig, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Create the masks using numpy indexing\n",
    "    mask1 = np.where(thresh == 0, 0, 255).astype('uint8')  # Foreground mask\n",
    "\n",
    "    # Convert the masks to images and save\n",
    "    Image.fromarray(mask1).save(os.path.join(save_dir, os.path.basename(image).replace('.jpg', '_mask.jpg')), \"JPEG\")\n",
    "    \n",
    "    # copy the original image to the image_save_dir\n",
    "    shutil.copy(os.path.join(images, image), os.path.join(image_save_dir, os.path.basename(image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now manually edit using photo editing tools (remove the non masked white parts and connect the parts of the plant where the tape was)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the segmentation points on the edited foreground picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./test', exist_ok=True)\n",
    "\n",
    "for idx, mask in enumerate(os.listdir(save_dir)):\n",
    "    image = Image.open(os.path.join(save_dir, mask)).convert(\"L\")\n",
    "    image_width, image_height = image.size\n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    binary_mask = image_array > 128\n",
    "    image_array_uint8 = np.uint8(binary_mask * 255)\n",
    "    \n",
    "    contours, _ = cv2.findContours(image_array_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    contours = [contour for contour in contours if cv2.contourArea(contour) > 100]\n",
    "    \n",
    "    # for testing purposes\n",
    "    image_bgr = cv2.cvtColor(image_array_uint8, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.drawContours(image_bgr, contours, -1, (255, 0, 0), 4)\n",
    "    contour_image = Image.fromarray(image_bgr)\n",
    "    contour_image.save(f'./test/{mask}')\n",
    "    \n",
    "    with open(os.path.join(label_save_dir, mask.replace('_mask.jpg', '.txt')), \"w\") as f:\n",
    "        for contour in contours:\n",
    "            normalized_contour_points = contour[:, 0, :] / [image_width, image_height]\n",
    "            normalized_contour_xyxyxy_format = normalized_contour_points.flatten().tolist()\n",
    "            f.write('0 ')\n",
    "            f.write(\" \".join(map(str, normalized_contour_xyxyxy_format)))\n",
    "            f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
